# System Design and Scalability

- **Caching**: used to speed up requests. If data is accessed frequently store it there so it can be retrived quickly. Example: user sessions, fully rendered blog articles, activity streams, user<->friend relationships
  - Consider: cache data may be inconsistent, cache data has to be small, eviction policy of cache such as - Least Recently Used (LRU), Least Frequently Used (LFU), Most Recently Used (MRU)
  - **Distributed Cache**: hold data in memory. Not source of truth and can hold limited amount of data(based on size of memory of host)
    - **Memcached**: simple, fast key value storage
    - **Redis**: same as memcached but can do more. Can be set up as a cluster to increase availability and data replication
- **Performance vs Scalability**
  - Service is scalable if resources added to system results in increased performance in a manner proportional to the resources added.
  - Performance problem if system is slow for a single user.
  - Scalability problem if system is fast for a single user but slow under heavy load.
    - **Vertical Scaling**: scale up, add resources to a single node system. Expensive and there is limitation
    - **Horizontal Scaling**: scale out, infinite hosts but have to deal with distributed systems.
- **Latency vs Throughput**
  - **Latency**: time to perform some action or to produce some result. Latency us measured in units of time - hours, minutes, seconds, nanoseconds, or clock periods.
  - **Throughput**: number of actions or results per unit of time. This is measured in units of whatever is being produced per unit of time.
  - Aim for maximal throughput with acceptable latency.
- **Availability vs Consistency**
  - **Consistency**: every read receives the most recent write or an error
    - **Weak Consistency**: after a write, reads may or may not see it.
      - Seen in systems such as memcached.
      - Works well with use cases like VoIP, video chat, and realtime multiplayer games.
    - **Eventual Consistency**: after a write, reads will eventually see it (typically within milliseconds). Data is replicated asynchronously.
      - Seen in systems with high availability.
      - Works well with use cases such as DNS, email.
      - Amazon S3, SimpleDB
    - **Strong Consistency**: after a write, reads will see it. Data is replicated synchronously
      - Seen in systems that need transactions
      - Seen in file systems and Relational Data Management Systems (RDBMS)
  - **Availability**: every request receives a response, without a guarantee that it contains the most recent version of the information
    - **Fail-over**: standby equipment automatically takes over if main system fails. Disadvantages: more hardware and additional complexity, there is a potential for loss of data if the active system fails before any newly written data can be replicated to the passive
      - **Active-passive**: heartbeats are sent between active and passive server on standby. If heartbeat is interrupted, the passive server takes over the active's IP address and resumes service.
        - can also be referred to as master-slave failover.
      - **Active-active**: both servers are managing traffic, spreading the load between them.
        - can also be referred to as master-master failover.
    - **Replication**
      - **Master-slave**: master serves reads and write, replicating writes to one or more slaves, which serve only reads. Slaves can also replicate to additional slaves in a tree-like fashion. If the master goes offline, the system can continue to operate in read-only mode until a slave is promoted to a master or a new master is provisioned.
      - **Master-Master**: both masters serve reads and writes and collaborate with each other on write. If either master goes down, the system can continue to operate with both reads and writes.
      - [**Buddy Replication**](https://access.redhat.com/documentation/en-us/jboss_enterprise_application_platform/4.3/html/cache_tree_cache_guide/clustered_cache___using_replication-buddy_replication): suppress replicating your data to all instances in a cluster. Instead, each instance picks one or more 'buddies' in the cluster, and only replicates to these specific buddies. This greatly helps scalability as there is no longer a memory and network traffic impact every time another instance is added to a cluster.
        - Benefitial only if a certain data is frequently accessed it is served from one instance rather than a round-robin fashion. Ex: sticky sessions
  - **Partition Tolerance**: system continues to operate despite arbitrary partitioning due to network failures. Only network failure will cause system to respond incorrectly
  - **Brewer's CAP theorem**. In distributed system only support two of three at any given point in time. In centralized system we don't have network partions, so we can get both availability and consistency.
    - **Consistency and partition tolerance (CP)**: data is consistent between all nodes, and maintains partition tolerance (preventing data desync) by becoming unavailable when a node goes down. Waiting for a response from a partitioned node might result in a timeout error. CP is good choice if business needs atomic reads and writes. Use: HBase, MongoDB, Redis, MemcacheDB, BigTable-like systems
    - **Availability and Partition Tolerance (AP)**: nodes remain online even if they can't communicate with each other and will resync data once the partition is resolved, but you aren't guaranteed that all nodes will have the same data (either during or after the partition). Responses return the most recent version of the data available on a node, which might not be the latest. Writes might take some tome to propagate when the partition is resolved. AP is a good choice if the business needs allow for eventual consistency or when the system needs to continue working despite external errors. Use: Voldemort, Riak, Cassandra, CouchDB, Dynamo-like systems
    - **Consistency and Availability (CA)**: not possible, it is a software tradeoff. You can choose what to do in the face of a network partition. Nodes remain online even if they can't communicate with each other and will resync data once the partition is resolved, but you aren't guaranteed that all nodes will have the same data (either during or after the partition). Use: Traditional relational databases like PostgreSQL, MySQL, etc.
- **Vertical Scaling**: scale up, add resources to a single node system. Expensive and there is hardware limitation. Ex: SQL
- **Horizontal Scaling**: scaling out using commodity machines is more cost efficient and results in higher availability than scaling up a single sever on more expensive hardware. Ex: load balancers, NoSQL
  - Disadvantages
    - scaling horizontally introduces complexity and involves cloning servers
      - servers should be stateless: they should not contain any user-related data like sessions or profile pictures
      - sessions can be stored in a centralized data store such as a database (SQL, NoSQL) or a persistent cache (Redis, Memcached)
    - downstream servers such as caches and databases need to handle more simultaneous connections as upstream servers scale out
- **Database**: electronic system that allows data to be easily accessed, manipulated, and updated.
  - **Relational Database Management System (RDBMS)**: relational database like SQL, Oracle is a collection of data items organized in tables. Highly-structued table organization with rigidly-defined data formats and record structure. Scales vertically, scaling reads difficult, scaling writes nearly impossible.
    - **ACID**: Set of properties of relational databse transactions intended to guarantee validity in the event of errors, power failures, etc.
      - **Atomicity**: each transaction is all of nothing
      - **Consistency**: any transaction will bring the database from one valid state to another
      - **Isolation**: executing transactions concurrently has the same results as if the transactions were executed serially.
      - **Durability**: guarantees that once a transaction has been committed, it will remain committed even in the case of a system failure (e.g., power outage or crash).
    - **Reasons for SQL**: consistent no room for error, structured data, strict schema, relational data, need for complex joins, transactions, lookups by index are fast
  - **NoSQL**: data items represented in key-value store, document store, wide column store, or graph database. Data is denormalized, and joins are generally done in the application code. Most NoSQL stores lack true ACID transactions in favour of eventual consistency. Scales horizontally and higher availability.
    - **BASE**: set properties of NoSQL database. Basically Available, Soft state, Eventual consistency. BASE system chooses availabilty over consistency.
      - **Basically available**: gurantees availability
      - **Soft state**: state of the system may change over time, wven without input
      - **Eventual consistency**: the system will become consistent over time, given that the system doesn't receive input during that time.
    - **Reasons for NoSQL**: budget won't allow large devices and must be put into lower performance devices, datastructures being managed is variable, analyzing large quantities of data in read mode only, non-relational data, no need for complex joins, store many TB (or PB) of data
      - leaderboard or scoring data, temporary data like shopping cart, lookup tables, frequently accessed tables, log data
    - **Key-Value Store**: O(1) reads and writesand is often backed by memory or SSD.
      - Abstraction: hash table
      - High performance and are often used for simple data models or for rapidly-changing data, such as an in-memory cache layer. Since they offer a limited set of operations, complexity is shifted to the application layer if additional operations are needed.
      - Key-value store is the basis for more compex system such as document store and a graph database.
      - Key is auto-generated while value can be String, JSON, Blob etc.
      - Example: Amazon S3
    - **Document Store**: document store in centered around documents where a document stores all information for a given object. Docuent stores provide APIs or a query language to query based on the internal structure of the document itself.
      - Abstraction: key-value store with documents stored as values
      - Documents are organized by collections, tags, metadata, or directories. Although documents can be organized or grouped together, documents may have fields that are completely different from each other
      - documents stores provide a high flexibility and are often used for working with ocassionally changing data
      - document data is stored as XML, JSON, binary etc
      - schema-less, makes adding fields to JSON documents a simple task without having to define changes first
      - Example: MongoDB, CouchDB, DynamoDB
    - **Wide Column Store**: basic unit of data is a column (name/value pair). A column can be grouped in column families(analogous to a SQL table). Super column families further group column families. Column families can contain virtually unlimited number of columns that can be created at runtime or the definition of the schema. Each column can be accessed independently with a row key, and columns with the same row key form a row. Each value contains a timestamp for versioning and for conflict resolution.
      - Abstraction: nested map ColumnFamily<RowKey, Columns<ColKey, Value, Timestamp>>
      - Offer high availability and high scalability. They are often used for very large data sets.
      - Example: BigTable, HBase, Cassandra
    - **Graph Database**: each node is a record and each arc is a relationship between two nodes. Graph databases are optimized to represent complex relationships with many foreign keys or many-to-many relationships.
      - Abstraction: graph
      - Offer high performance for data models with complex relationships, such as a social network.
      - Relatively new and are not yet widely-used; it might be more difficult to find development tools and resources.
      - Many graphs can only be accessed with REST APIs
      - Example: Neo4j, FlockDB
  - **Techniques to scale database**
    - **Replication**: frequent, automatic copying of data from a database of one computer or server to a database in another
      - **Master-slave replication**: master serves read and writes, replicating writes to one or more slaves, which serve only reads.Slaves can also replicate to additional slaves in a tree-like fashion. If the master goes offline, the system can continue to operate in read-only mode until a slave is promoted to a master or a new master is provided.
        - Disadvantages: additional logic is needed to promote a slave to master
      - **Master-master replication**: both masters serve reads and writes and coordinate with each other on writes. If either master goes down, the system can continue to operate with both reads and writes.
        - Disadvantages: need a loadbalancer or make changes to application logic to determine where to write, most master-master systems are either loosely consistent (violating ACID) or have increased write latency due to synchronization, conflict resolution comes more into play as more write nodes are added and as latency increases
      - **Buddy Replication**: suppress replicating your data to all instances in a cluster. Instead, each instance picks one or more 'buddies' in the cluster, and only replicates to these specific buddies. This greatly helps scalability as there is no longer a memory and network traffic impact every time another instance is added to a cluster.
        - Benefitial only if a certain data is frequently accessed it is served from one instance rather than a round-robin fashion. Ex: sticky sessions
      - Disadvantages of replication:
        - potential for loss of data if the msater fails before any newly written data can be replicated to other nodes
        - since writes are replayed to read replicas they might get bogged down if there are a lot of writes and can't do as many reads
        - increasing read slaves increases time to replicate which increases replication lag,
        - replication adds more hardware and additional complexity
    - **Functional Partitioning**: (or federation) splits up database into several smaller databases by function. Results in less read and write traffic to each smaller database and therefore less replication lag. Smaller databases result in more data that can fit in memory, which result in more cache hits due to improved cache locality. With no single central master serializing writes can be done in parallel, increasing throughput. This is done for manageability, performance or availability reasons, or load balancing.
      - Disadvantages: not effective if schema requires huge functions or tables, update application logic to determine which database to read and write, joining two databases is more complex with a server link, partitioning adds more hardware and additional complexity
    - **Sharding**: distributes data across different databases such that each database can only manage a subset of the data. As data increases more shards are added to the cluster. Common ways to shard a table of users is either through the user's last name initial or the user's geographic location.
      - **Consistent hashing**: once range of keys are spread across the available nodes, find the right node with the hash code for a key. Performs sharding nicely and elegantly. Reduces the amount of transferred data.
      - Advantages: less read and write traffic, less replication, and more cache hits. Index size is reduced, which generally improves performance with faster queries. If one shard goes down, the other shards are still operational, although some form of replication needs to be in place to prevent data loss. There is no single central master serializing writes, allowing you to write in parallel with increased throughput.
      - Disadvantages: application logic needs to be updated to word with shards, this means complex SQL queries. Some shards may deal with more load compared to others, therefore rebalancing needs to be done which adds complexity. Joing data from multiple shards is more complex. Sharding adds more hardware and additional complexity.
    - **Denormalization**: improves read performance at the expense of write performance. Redundant copies of the data are written in multiple tables to avoid expensive joins.
      - Advantages: Once data is distributed through partition or sharding, managing data becomes complex. Denormalization might circumvent complex joins. Some read operations may be expensive due to join and this helps circumvent that.
      - Disadvantages: Generally there are more reads than write. Data is duplicated. Constraints can help redundant copies of information stay in sync, which increases comlexity. Denormalized database under heavy write load might perform worse than its normalized counterpart.
    - **SQL tuning**: need to benchmark and profile to simulate and uncover bottlenecks.
      - **Benchmark**: simulate high-load situations with tools such as *ab*. **Profile**: enable tools such as the *slow query log* to help track performance issues. Optimizations that can be done with benchmark and profiling are
        - **Tighten up the schema**
          - MySQL dumps to disk in contiguous blocks for fast access
          - Use *CHAR* instead of *VARCHAR* for fixed-length fields
          - Use *TEXT* for large blocks of text such as blog posts. *TEXT* also allows for boolean searches. Using a *TEXT* field results in storing a pointer on a disk that is used to locate the text block.
          - Use *INT* for larger numbers up to 2^32 or 4 billion
          - Use *DECIMAL* for currency to avoid floating point representation errors.
          - Avoid storing large *BLOBS*, store the location of where to get the object instead
          - *VARCHAR(255)* is the largest number of characters that can be counted in a 8 bit number, often maximizing the use of a byte in some RDBMS.
          - Set the *NOT NULL* constraint where applicable to improve search performance.
        - **Use good indices**
          - columns that are being queried could be faster with indices
          - indices are usually represented as self-balancing B-tree that keeps data sorted and allows searches, sequential access, insertions, and deletions in logarithmic time
          - placing an index can keep the data in memory, requiring more space
          - writes could also be slower since the index also needs to be updated
          - when loading large amounts of data, it might be faster to disable indices, load the data, then rebuild the indices
        - **Avoid expensive joins**: denormalize where performance demands it
        - **Partition tables**: break up a table by putting hot spots in a seperate table to help keep it in memory.
        - **Tune the query cache**: in some cases the query cache could lead to performance issues.
    - [**More NoSQL patterns**](http://horicky.blogspot.com/2009/11/nosql-patterns.html)
- **Load Balancer**: distribute incoming client requests to computing resources such as application servers and database. Can be implemented with hardware (expensive) or with software such as HAProxy. It is common to set up multiple load balancers, either in *active-passive* or *active-active* mode. Can help with horizontal scaling, improving performance and availability.
  - Effective at
    - Preventing requests from going to unhealthy servers
    - Preventing overloading resources
    - Helping eliminate single points of failure
    - **SSL termination**: decrypt incoming requests and encrypt server responses so backed servers do not have to perform these potentially expensive operations
    - **Session persistence**: issue cookies and route a specific client's requests to same instance if the web apps do not keep track of sessions
  - Disadvantages
    - load balancer can become a bottleneck if it does not have enough resources or if it is not configured properly
    - introducing a load balancer to help eliminate single points of failure results in increased complexity
    - single load balancer is a single point of failure, configuring multiple load balancers further increases complexity
  - Can route traffic based on various metrics, including:
    - **Random**
    - **Least loaded**
    - **Session/cookies**
    - **Round robin or weighted round robin**: each server is assigned a value relative to other servers in the pool. This "weight" determines how many more or fewer requests are sent that server's way; compared to other servers in the pools
    - **Layer 4**: looks at *transport layer* from OSI layer model to decide how to distribute requests. Involves source and destination IP addresses, and ports in the header, but not contents of the packet.
    - **Layer 7**: looks at *application layer* from OSI layer model to decide how to distribute requests. This can involve contents of the header, message, and cookies. It can terminate network traffic, read message, make load-balancing decision, then open a connection to the selected server. Layer 4 requires less time and computing resources at the cost of flexibility, but the performance impact is minimal on hardware. Layer 7 is more preferred.
- **Reverse Proxy (Web Server)**: web server that centralizes internal services and provides unified interfaces to the public. Requests from clients are forwarded to a server that can fulfill it before the reverse proxy returns the server's response to the client.
  - Benefits
    - **Increased security**: hide information about backend servers, blacklist IPs, limit number of connections per client
    - **Increased scalability and flexibility**: clients only see the reverse proxy's IP, allowing to scale servers or change their configuration
    - **SSL termination**: decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations
    - **Compression**: compress server responses
    - **Caching**: return the response for cached requests
    - **Static content**: server static content directly. Ex: html/css/js, photos etc
  - Disadvantages
    - results in increased complexity
    - single proxy is a single point of failure, configuring multiple reverse proxies (ie failover) further increases complexity
- **Load Balancer vs Reverse Proxy**: load balancer is useful for multiple servers while reverse proxy can be useful with even just one web server or application server
- **Content Delivery Network (CDN)**: globally distributed network of proxy servers, serving from locations closer to the user. Generally, it is static content such as HTML, CSS, JS, photos, videos, but it can also be dynamic content.
  - Advantages
    - Users receive content from data centers close to them
    - Servers do not have to serve requests that the CDN fulfills
  - Disadvantages
    - CDN cost could be significant depending on traffic
    - Content might be stale if it is updated before the time-to-live(TTL) expires it.
    - CDNs require changing URLs for static content to point to the CDN
  - **Push CDNs**: receive content whenever changes occur on server. You take full responsibility for providing content, uploading directly to CDN, and rewriting URLs to point to CDNS.
    - Content is uploaded only when it is new or changed, minimizing traffic, but maximizing storage.
    - Sites with small amount of traffic or sites with content that isn't often updated work well. Content is placed on CDNs once, instead of being re-pulled at regular intervals.
  - **Pull CDNs**: grab new content from server when the first user requests it. Leave content on the server and rewrite URLs to point to the CDN. Results in slower request until content is cached on the CDN. TTL determines how long content is cached.
    - Minimize storage space on the CDN, but can create redundant traffic if files expire and are pulled before they have actually changed.
    - Sites with heavy traffic work well, as traffic is spread out more evenly with only recently-requested content remaining on CDN.
- **Domain Name System (DNS)**: translates a domain name such as www.example.com to IP address. 
  - Disadvantages: slight delay, DNS server management could be complex (done by government, ISPs), Denial of Service(DDoS) attack
  - Services like CloudFlare can route traffics through various methods
    - [**Weighted round robin**](http://g33kinfo.com/info/archives/2657): each server is assigned a value relative to other servers in the pool. This "weight" determines how many more or fewer requests are sent that server's way; compared to other servers in the pools
      - Prevent traffic from going to servers under maintenance
      - Balance between varying cluster sizes
      - A/B testing
    - Latency based
    - Geolocation-based
  - **NX record (name server)**: specifies the DNS servers for your domain/subdomain
  - **MX record (mail exchange)**: specifies the mail servers for accepting messages.
  - **A record (address)**: points a name to an IP address
  - **CNAME (canonical)**: Points a name to another name, CNAME (example.com to www.example.com) or to an A record
- **Readundant Array of Independent Disks(RAID)**: assumes there are multiple hard drives.
  - **RAID 0**: segment logically sequential data between 2 hard drives (striping). This decreases write time
  - **RAID 1**: mirror data, write data in two places in parallel. This way even if one drive dies the other can still serve data.
  - **RAID 5**:  4-5 drives and one is used for redundancy. If one fails can be retrieved
  - **RAID 6**: 4-5 drives and one is used for redundancy. If 1-2 fails can be retrieved
  - **RAID 10**: four drives. Combination of Raid 0 and Raid 1, where it provides both striping and redundancy.

## Sources

- [System Design Primer](https://github.com/donnemartin/system-design-primer)
- [Scalability, Availability & Stability Patterns](https://www.slideshare.net/jboner/scalability-availability-stability-patterns)
- [System Design Interview](https://github.com/checkcheckzz/system-design-interview)
- [System Design](https://github.com/shashank88/system_design)

## Additional sources to consult

- https://lethain.com/introduction-to-architecting-systems-for-scale/
- https://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview
- Microservices
- Zookeeper
- NGINX
- Web 1.0, 2.0, 3.0
- Operating system
- add blockchain to database
- previous scalability notes
- general designs different companies
- desgin patterns
- tools to know
- microservices
- websocket vs polling
- graphql
- redis
- memcached